# ðŸ”° User Manual for `anita_interface.py`

> This file serves as the user manual for interacting with [`anita_interface.py`](https://github.com/choH/half_tael_DQN/blob/master/anita/anita_interface.py).
>
> ðŸ“Œ v1.0 | 2019-08-29 | Henry Zhong

---

Note the current version of [`anita_interface.py`](https://github.com/choH/half_tael_DQN/blob/master/anita/anita_interface.py) is a rather oversimplified demo to show:
1. A very simple and unrefined way to construct `Anita_Persona` with `Anita_Trait`.
2. A very simple and unrefined way to couple `anita_interface.py` together with [`FX_env.py`](https://github.com/choH/half_tael_DQN/blob/master/DQN_v3.0/FX_env.py).

The implementation of `Anita` is premature at this stage, **it is encouraged to refactor the structure of `anita_interface.py` if you have conducted a more thoughtful consideration**. For now, the code is produced mostly as a general and straightforward guidance of how can `Anita` â€” *the persona-driven adjustments* â€” work within a DQN setting.

---
## 1. What does [`anita_interface.py`](https://github.com/choH/half_tael_DQN/blob/master/anita/anita_interface.py) do?

It creates a "human-like" avatar â€” named as `Anita_Persona` â€” with respect to the [OCEAN personality model](https://en.wikipedia.org/wiki/Big_Five_personality_traits). It is [Graphen's believe](https://www.graphen.ai/dev/anita/) that a trait â€”Â named as `Anita_Trait`, as for O-C-E-A-N in this case â€” of a person can be defined with the aid of statistical approaches (e.g. technical analysis). Graphen further believes by giving the supposedly "emotionally-distanced" trading bot a "human-like" intelligent avatar, it would be easier to deliver the concepts of such a product to clients; and therefore, gains more trust from clients.

In short, `Anita_Trait` will detect if a (set of) trading signal(s) generated by the model is preferable by a given personality trait or not. e.g. a very frequent trading behavior can be bad for "Conscientiousness".
We further combine different traits with adjustable weights to form a human-like avatar, named as `Anita_Persona`. `anita_interface.py` should be able to tell if such a (set of) trading signal(s) generated by the model is preferable by this `Anita_Persona` or not, and therefore influents the `reward` (in `FX_env.py`) of the model accordingly.

For example, if an `Anita_Persona` who attaches great importance to "Conscientiousness" was set to evaluate a set of rather random and frequent trade signals, it will give some very negative feedback (negative rewards). And through training with such a constraint, the model may adopt a trading strategy in compliance with the given `Anita_Persona` â€” in this case, a more "patient" trading strategy with less trade executions.


## 2. Coupling with [`FX_env.py`](https://github.com/choH/half_tael_DQN/blob/master/DQN_v3.0/FX_env.py)

In [`model_config.py`](https://github.com/choH/half_tael_DQN/blob/master/model_config.py), set:
```
config_anita_switch = True
```

Which will trigger:
```
final_reward = reward
if self.anita_switch == True and reward != 0:
    TI_AT = copy.deepcopy(self.TI_train)
    AT_reward = AT(TI_AT, self.n_features, self.n_actions)
    AP_reward = AP('Anita_placeholder_avatar', AT_reward)
    final_reward = reward + AP_reward.anita_reward
    print('$$ Final reward ({}) = DQN reward ({}) + Anita reward ({}) $$'.format(final_reward, reward, AP_reward.anita_reward))
```


## 3. Supported Methods

## 3.1. Anita_Persona

### 3.1.1. Anita_Persona(self, _avatar_name, _AT, _trait_weight_dict = default_trait_weight_dict)
**`_trait_weight_dict`**
* `dict` with structure as
    ```
    {'O_weight': var, 'C_weight': var, 'E_weight': var, 'A_weight': var, 'N_weight': var}`
    ```
    where `var` should be a numeric value.

* `default_trait_weight_dict` as
    ```
    {'O_weight': 1, 'C_weight': 1, 'E_weight': 1, 'A_weight': 1, 'N_weight': 1}
    ```
    represents a neutral avatar.


## 3.2. Anita_Trait


### 3.2.1. if_more_hold(self)
Determine if the `hold` action were executed more than its statistical average (more than `self.n_features/self.n_actions`).

**This is only a placeholder method.**


## 4. Sample Output

```
$$ Final reward (0.0) = DQN reward (1) + Anita reward (-1.0) $$
```

---

## 5. Vision and Legacy

Checkout [Issue #22: VISION of this project.](https://github.com/choH/half_tael_DQN/issues/22) for potential improvement on Anita.

The [legacy version of Anita](https://github.com/choH/half_tael_DQN/tree/master/legacy_ref/legacy_anita), drafted by Emil Qiu, was deprecated due to incompatible with this project. Checkout [this development journal in CHANGELOG.md](https://github.com/choH/half_tael_DQN/blob/master/CHANGELOG.md#2019-08-08--legacy-anita-plot-hole-discovered--henry) for details.